{
  "name": "Luke.GitHub.io",
  "tagline": "configuring elasticsearch cluster",
  "body": "h2. elasticsearch 설치\r\n\r\nh3. version\r\n\r\n> os : ubuntu 16.04.1-server-amd64\r\n> elasticsearch : 2.3.1\r\n> jdk : 8\r\n\r\nh3. openjdk 설치\r\n\r\n* sudo apt-get update 실행\r\n* sudo apt-get install openjdk-8-jre 실행\r\n\r\nh3. elasticsearch 설치\r\n\r\n* apt-get 으로 설치하면 2.3 버전이 설치되지 않는다. 어떻게 해야 apt-get 으로 2.3을 설치할 수 있는지 잘 모르겠음\r\n* 아래 명령을 실행 하여 다운로드\r\n<pre>\r\nwget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/deb/elasticsearch/2.3.1/elasticsearch-2.3.1.deb\r\n</pre>\r\n* sudo dpkg -i elasticsearch-2.3.1.deb 실행 \r\n* 이렇게 설치하면 설정파일 권한을 설정해 줘야한다.\r\n> * su 실행\r\n> * chmod -R 755 /etc/elasticsearch\r\n> * exit 실행\r\n> * sudo chmod -x /etc/elasticseearch/elasticsearch.yml\r\n> * sudo chmod -x /etc/elasticseearch/logging.yml\r\n* 설정파일을 심볼릭링크 걸어줘야한다.\r\n> * sudo ln -s /etc/elasticsearch /usr/share/elasticsearch/config 실행\r\n\r\nh2. elasticsearch 설정\r\n\r\nh3. 기본 설정\r\n\r\n* sudo vim /etc/hosts 실행\r\n> * cluster를 구성할 node(각 서버)들의 ip를 hostname 으로 등록한다. (hostname은 /etc/hostname 에서 확인할 수 있다.)\r\n\r\n* sudo vim /etc/elasticsearch/elasticsearch.yml 실행\r\n> * cluster.name: 클러스터이름 (하나의 클러스터로 연결시키기 위해서는 모든 노드가 같은 이름을 사용해야 한다.)\r\n> * node.name : ${HOSTNAME} (hostname을 nodename 으로 사용하도록 한다.)\r\n> * network.host: 0.0.0.0 (기본, 내부망으로 사용하도록 해야한다.)\r\n> * http.port : 9200 (기본)\r\n> * discovery.zen.ping.unicast.hosts: [\"\", \"\", ...] (cluster를 구성할 node들의 nodename(hostname)을 입력한다. ex. \"node01\", \"node02\", \"node03\"...)\r\n> * discovery.zen.join_timeout: 15s (추가)\r\n* sudo vim /usr/share/elasticsearch/bin/elasticsearch 실행\r\n> * ES_JAVA_OPTS=\"-Des.insecure.allow.root=true\" 추가 (root 권한으로 실행할 수 있게 함)\r\n\r\nh3. 메모리 설정\r\n\r\n* 메모리 swap 방지를 해서 속도 저하를 방지한다.\r\n\r\n* sudo vim /etc/elasticsearch/elasticsearch.yml 실행\r\n> * bootstrap.mlockall: true 로 설정\r\n* sudo vim /etc/default/elasticsearch 실행\r\n> * ES_HEAP_SIZE=2g (주석해제 후 수정, 만약 서버장비의 메모리가 4g라면, 2g를입력한다. 즉, 램의 50% 용량을 입력하면 된다.)\r\n> * MAX_LOCKED_MEMORY=unlimited (주석 해제)\r\n* http://localhost:9200/_nodes/process?pretty 입력 후 \"mlockall\"이 true 로 되어 있으면 잘 설정된 것이다. 만약 true로 안되어 있는 경우는 service 로 실행시켜서 설정 파일이 제대로 적용되지 않은 것이나 ES_HEAP_SIZE 의 값을 너무 크게 입력한 것이다.\r\n\r\nh3. 최대 open 파일 개수 설정\r\n\r\n* OS level\r\n> * ulimit -n (내 계정에 허용된 최대 open 파일 개수이다.)\r\n> * sudo vim /etc/security/limits.conf 실행 한 후 아래 내용 입력 (\"계정\"은 실제 elasticsearch를 실행할 계정명으로 교체)\r\n> > * root soft nofile 131070\r\n> > * root hart nofile 131070\r\n> > * root soft memlock unlimited\r\n> > * root hart memlock unlimited\r\n> > * 계정 soft nofile 131070\r\n> > * 계정 hart nofile 131070\r\n> > * 계정 soft memlock unlimited\r\n> > * 계정 hart memlock unlimited\r\n> * sudo vim /etc/pam.d/common-session 실행\r\n> > * session required pam_limits.so 입력\r\n> * sudo vim /etc/pam.d/common-session-noninteractive\r\n> > * session required pam_limits.so 입력\r\n> * *재부팅*\r\n> * ulimit -n 으로 수치 변경된 것 확인\r\n\r\n* application level\r\n> * cat /proc/\"PID\"/limits | grep \"Max open files\" (\"PID\"는 실제 elasticsearchd의 pid로 교체)를 실행하면 elasticsearch가 열 수 있는 최대 파일 갯수가 나온다. \r\n> * sudo vim /etc/default/elasticsearch 실행\r\n> > * MAX_OPEN_FILES=131070 (주석 해제, 값은 128k 이다.)\r\n> * http://localhost:9200/_nodes/stats/process?pretty 에서 \"max_file_descriptors\" 확인\r\n\r\n* 이래도 바뀌지 않을 경우\r\n> * sudo vim /etc/supervisor/supervisord.conf 실행 (이 파일이 없을 수도 있다. 없으면 위에 설정 바꾼 것만으로 적용이 될 것이다.)\r\n> * minfds=131070 추가\r\n> * sudo service supervisor restart 실행\r\n> 값 바뀐 것 확인\r\n\r\nh3. dedicated master 설정\r\n\r\n* configure dedicated master node\r\n> * sudo vim /etc/elasticsearch/elasticsearch.yml 실행\r\n> > * node.master: true (추가)\r\n> > * node.data: false (추가)\r\n> > * discovery.zen.minimum_master_node: n (주석해제 후 n 값 설정, number of total nodes / 2 + 1, ex. 3(master+2 of data) / 2 + 1 = 2, 값은 정수로 반내림한다.)\r\n* configure data nodes\r\n> * sudo vim /etc/elasticsearch/elasticsearch.yml 실행\r\n> > * discovery.zen.minimum_master_node: n (주석해제 후 n 값 설정, number of total nodes / 2 + 1, ex. 3(master+2 of data) / 2 + 1 = 2, 값은 정수로 반내림한다.)\r\n> > * *아래 설정 추가하면 dedicated data node로 세팅할 수 있지만 하지 않는다. 이유는, master node에 문제가 생겼을 때, 대신 master node 역할을 수행할 수 있게 하기 위함이다.*\r\n> > > * -node.master: false (추가)-\r\n> > > * -node.data: true (추가)-\r\n\r\n\r\nh2. elasticsearch 실행, 종료 방법\r\n\r\n* sudo /usr/share/elasticsearch/bin/elasticsearch -d : 데몬으로 실행\r\n* sudo kil -9 pid : 데몬 종료\r\n* sudo service elasticsearch start(stop, restart) : 서비스로 실행, 종료 (하지만 이 방법을 사용하면 /usr/share/elasticsearch/bin/elasticsearch 안에 들어 있는 옵션 설정이 적용되지 않는다.\r\n\r\nh2. head plugin 설치\r\n\r\n* sudo /usr/share/elasticsearch/bin/plugin install mobz/elasticsearch-head 실행\r\n* http://localhost:9200/_plugin/head/ 접속\r\n\r\nh2. elasticsearch 접속\r\n\r\n* 꼭 master 노드로 데이터를 날려야하는 것은 아니고, 아무 node 에나 접속해서 데이터를 날리면 된다.\r\n* chrome의 postman 이란 확장 어플리케이션을 사용하면 테스트하기가 수월하다.\r\n* ex. 주소창에 localhost:9200/test/log-20160804/1 라고 입력 후 body에 jason 형태로 데이터를 입력하고 날리는 방식은 \"PUT\"으로 날리면 된다.\r\n* 입력한 데이터의 정보는 다음과 같다.\r\n> * localhost:9200 (node, rdb에서의 dbserver)\r\n> * test (index, rdb에서의 db)\r\n> * log-20160804 (type, rdb에서의 table)\r\n> * 1 (document, rdb에서의 row?)\r\n> * jason 의 key:value (field, rdb에서의 column?)\r\n\r\n* PUT : 특정 document를 지정하여 데이터를 저장한다. (ex. localhost:9200/test/log-20160804/1)\r\n* POST : document 를 자동으로 생성하여 데이터를 저장한다. (ex. localhost:9200/test/log-20160804)\r\n* GET : 특정 document에 대한 데이터 조회\r\n* DELETE : 데이터 삭제\r\n\r\n\r\nh2. refefences\r\n\r\n* https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-16-04\r\n* https://www.digitalocean.com/community/tutorials/how-to-set-up-a-production-elasticsearch-cluster-on-ubuntu-14-04\r\n* https://underyx.me/2015/05/18/raising-the-maximum-number-of-file-descriptors",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}